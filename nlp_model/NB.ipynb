{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Category                                            Message\n",
      "0         ham  Go until jurong point, crazy.. Available only ...\n",
      "1         ham                      Ok lar... Joking wif u oni...\n",
      "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3         ham  U dun say so early hor... U c already then say...\n",
      "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
      "...       ...                                                ...\n",
      "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
      "5568      ham               Will ü b going to esplanade fr home?\n",
      "5569      ham  Pity, * was in mood for that. So...any other s...\n",
      "5570      ham  The guy did some bitching but I acted like i'd...\n",
      "5571      ham                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./spam.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = 0\n",
    "\n",
    "def transform(text):\n",
    "    if text == 'spam':\n",
    "        return 1\n",
    "    if text == 'ham':\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def standardize(text):\n",
    "    data = []\n",
    "    for word in text.split():\n",
    "        if word not in stopword:\n",
    "            word = lemmatizer.lemmatize(word, \"n\")\n",
    "            word = lemmatizer.lemmatize(word, \"v\")\n",
    "            word = lemmatizer.lemmatize(word, \"a\")\n",
    "            data.append(word)\n",
    "    return ' '.join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go jurong point crazy available bugis n great world la e buffet cine get amore wat\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = text.replace({'<.*?>': ''}, regex = True)\n",
    "    text = text.replace({'[^A-Za-z]': ' '}, regex = True)\n",
    "    text = text.str.replace('http\\S+', ' ')\n",
    "    text = text.str.replace('\\W', ' ')\n",
    "    text = text.str.replace('\\d', ' ')\n",
    "    text = text.str.lower()\n",
    "    text = text.apply(standardize)\n",
    "    return text\n",
    "\n",
    "data['Message'] = preprocess(data['Message'])\n",
    "print(data['Message'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1114                          good movie ok leave hourish\n",
      "3589    free give otherwise nalla adi entey nattil kittum\n",
      "3095             emigrate something ok maybe bite hopeful\n",
      "1012                            get home babe still awake\n",
      "3320                                    kay since already\n",
      "                              ...                        \n",
      "4931    hi sexychat girl wait text text great night ch...\n",
      "3264                                  u gonna get deus ex\n",
      "1653    ur chance win cash every wk txt action c www m...\n",
      "2607                    r u sam p eachother meet go house\n",
      "2732                  mm feel sleepy today shall get dear\n",
      "Name: Message, Length: 4457, dtype: object 4456    storm msg wen u lift phne u say hello u knw wt...\n",
      "690           please call immediately urgent message wait\n",
      "944     also sorta blow couple time recently id rather...\n",
      "3768                            sir goodmorning free call\n",
      "1189             come alive good correct good look figure\n",
      "                              ...                        \n",
      "2906    ha know either clever simple thing pear day pe...\n",
      "1270                       tee hee lecture cheery bye bye\n",
      "3944    get call landline number ask come anna nagar g...\n",
      "2124                                                error\n",
      "253                                                      \n",
      "Name: Message, Length: 1115, dtype: object 1114    0\n",
      "3589    0\n",
      "3095    0\n",
      "1012    0\n",
      "3320    0\n",
      "       ..\n",
      "4931    1\n",
      "3264    0\n",
      "1653    1\n",
      "2607    0\n",
      "2732    0\n",
      "Name: label, Length: 4457, dtype: int64 4456    0\n",
      "690     1\n",
      "944     0\n",
      "3768    0\n",
      "1189    0\n",
      "       ..\n",
      "2906    0\n",
      "1270    0\n",
      "3944    0\n",
      "2124    1\n",
      "253     0\n",
      "Name: label, Length: 1115, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data['label'] = data['Category'].apply(transform)\n",
    "X = data[\"Message\"]\n",
    "Y = data[\"label\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "print(X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'ok', 'leave', 'free', 'give', 'something', 'get', 'home', 'babe', 'still', 'already', 'say', 'oh', 'yeah', 'sorry', 'thing', 'late', 'call', 'even', 'dear', 'look', 'want', 'night', 'pick', 'u', 'da', 'soon', 'co', 'e', 'c', 'way', 'ur', 'ask', 'come', 'x', 'take', 'gonna', 'buy', 'place', 'tonight', 'work', 'time', 'would', 'pls', 'go', 'wait', 'hope', 'great', 'day', 'r', 'tell', 'find', 'much', 'use', 'reply', 'know', 'today', 'right', 'make', 'sure', 'really', 'n', 'help', 'mobile', 'love', 'watch', 'week', 'im', 'thank', 'uk', 'please', 'yes', 'lor', 'keep', 'anything', 'need', 'life', 'think', 'first', 'guy', 'last', 'let', 'nokia', 'win', 'send', 'see', 'min', 'wat', 'miss', 'money', 'service', 'cash', 'prize', 'k', 'stop', 'b', 'morning', 'sleep', 'well', 'number', 'smile', 'like', 'care', 'happy', 'also', 'feel', 'wish', 'hey', 'p', 'msg', 'lol', 'amp', 'tomorrow', 'try', 'message', 'gud', 'show', 'text', 'dont', 'lt', 'gt', 'new', 'year', 'end', 'nice', 'finish', 'one', 'back', 'com', 'txt', 'meet', 'friend', 'cant', 'start', 'tone', 'contact', 'box', 'phone', 'hi', 'every', 'claim', 'urgent', 'www']\n",
      "143\n"
     ]
    }
   ],
   "source": [
    "vocabulary = []\n",
    "for text in X_train:\n",
    "    for word in text.split():\n",
    "        vocabulary.append(word)\n",
    "\n",
    "dictionary = Counter(vocabulary)\n",
    "vocabulary = []\n",
    "for item in dictionary:\n",
    "    if dictionary[item] >= 50:\n",
    "        vocabulary.append(item)\n",
    "\n",
    "print(vocabulary)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(text):\n",
    "    data = []\n",
    "    for word in text.split():\n",
    "        if word in vocabulary:\n",
    "            data.append(word)\n",
    "    return ' '.join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1114                                        good ok leave\n",
      "3589                                            free give\n",
      "3095                                         something ok\n",
      "1012                                  get home babe still\n",
      "3320                                              already\n",
      "                              ...                        \n",
      "4931    hi wait text text great night send stop stop s...\n",
      "3264                                          u gonna get\n",
      "1653                      ur win cash every txt c www x p\n",
      "2607                                        r u p meet go\n",
      "2732                                  feel today get dear\n",
      "Name: Message, Length: 4457, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def filterReview(text):\n",
    "    text = text.apply(filter)\n",
    "    return text\n",
    "\n",
    "X_train = filterReview(X_train)\n",
    "X_test = filterReview(X_test)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 35)\t1\n",
      "  (0, 77)\t1\n",
      "  (0, 51)\t1\n",
      "  (1, 29)\t1\n",
      "  (1, 32)\t1\n",
      "  (2, 77)\t1\n",
      "  (2, 95)\t1\n",
      "  (3, 31)\t1\n",
      "  (3, 44)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 99)\t1\n",
      "  (4, 0)\t1\n",
      "  (5, 31)\t1\n",
      "  (6, 88)\t2\n",
      "  (7, 76)\t1\n",
      "  (7, 131)\t1\n",
      "  (8, 31)\t1\n",
      "  (8, 97)\t1\n",
      "  (8, 106)\t1\n",
      "  (8, 50)\t1\n",
      "  (9, 9)\t1\n",
      "  (9, 23)\t1\n",
      "  (10, 20)\t1\n",
      "  (11, 31)\t1\n",
      "  (11, 56)\t1\n",
      "  :\t:\n",
      "  (4450, 71)\t1\n",
      "  (4450, 132)\t1\n",
      "  (4451, 77)\t1\n",
      "  (4452, 73)\t1\n",
      "  (4452, 119)\t1\n",
      "  (4452, 36)\t1\n",
      "  (4452, 90)\t1\n",
      "  (4452, 91)\t1\n",
      "  (4452, 100)\t2\n",
      "  (4452, 104)\t2\n",
      "  (4452, 43)\t1\n",
      "  (4453, 31)\t1\n",
      "  (4453, 34)\t1\n",
      "  (4454, 116)\t1\n",
      "  (4454, 126)\t1\n",
      "  (4454, 12)\t1\n",
      "  (4454, 114)\t1\n",
      "  (4454, 24)\t1\n",
      "  (4454, 130)\t1\n",
      "  (4455, 33)\t1\n",
      "  (4455, 61)\t1\n",
      "  (4456, 31)\t1\n",
      "  (4456, 20)\t1\n",
      "  (4456, 109)\t1\n",
      "  (4456, 25)\t1\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "features_CV = cv.fit_transform(X_train)\n",
    "features_test_cv = cv.transform(X_test)\n",
    "\n",
    "print(features_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, gamma=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, gamma=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, gamma=0.01)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = svm.SVC( C = 100, gamma = 0.01)\n",
    "model_svm.fit(features_CV, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "Accuracy:  97.75784753363229\n",
      "Precision:  97.2027972027972\n",
      "Recall:  86.875\n",
      "Confusion Matrix:  [[951   4]\n",
      " [ 21 139]]\n",
      "********************************************************\n"
     ]
    }
   ],
   "source": [
    "Y_preds_svm = model_svm.predict(features_test_cv)\n",
    "print('SVM:')\n",
    "print('Accuracy: ', accuracy_score(Y_test, Y_preds_svm)*100)\n",
    "print('Precision: ', precision_score(Y_test, Y_preds_svm)*100)\n",
    "print('Recall: ', recall_score(Y_test, Y_preds_svm)*100)\n",
    "print('Confusion Matrix: ', confusion_matrix(Y_test, Y_preds_svm))\n",
    "print('********************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_svm']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model_svm, 'model_svm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
